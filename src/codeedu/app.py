'''
 # @ Author: Jianing ZHAO
 # @ Create Time: 2025-05-26 17:54:25
 # @ Modified by: Jianing ZHAO
 # @ Modified time: 2025-05-28 14:08:11
 # @ Description: @Deprecated
 '''

from flask import Flask, Response, stream_with_context,request,jsonify
import sys
import threading
import queue
import io
import time
from crewai import Crew,Agent,Task,Process # å‡è®¾ä½ å·²ç»æœ‰ agents å’Œ tasks æ„å»ºå¥½äº†
from crewai_tools import SerperDevTool,CodeInterpreterTool,FileWriterTool

#from langchain.memory import ConversationBufferMemory

#from langchain_core.prompts import ChatPromptTemplate
import json
import re
import uuid
import glob
from crewai import LLM
import os
import html
from flask import send_from_directory
from flask_cors import CORS
from agent_pool import planner, researcher, reporting_analyst, programmer, educator,agents_config,executor,chat_agent
from task import distribute_task, code_task, reporting_task, tasks_config,research_task,education_task,code_analysis_task,generate_quiz_task,greeting_task
from utils.intention import should_greet_or_chitchat,summarize_thoughts_stream
#src.codeedu.task 
from pathlib import Path

app = Flask(__name__)
CORS(app)
OUTPUT_DIR =Path(__file__).parent / "output"
STORAGE_PATH = Path(__file__).parent / "conversations" 
#print(STORAGE_PATH)
#print("**********")
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(STORAGE_PATH, exist_ok=True)
  # user_id or convo_id â†’ {'crew': ..., 'memory': ..., 'history': [...]}
# é˜Ÿåˆ—å­˜å‚¨æ—¥å¿—
#log_queue = queue.Queue()
log_queue_thought = queue.Queue()
log_queue_result = queue.Queue()
internal_thought_log = [] #è®°å½• raw_thought

agents_dict = {
  'researcher': {"id": "researcher", "configuration": agents_config["researcher"], "agent": researcher},
  'reporting_analyst': {"id": "reporting_analyst", "configuration": agents_config["reporting_analyst"], "agent": reporting_analyst},
  'programmer': {"id": "programmer", "configuration": agents_config["programmer"], "agent": programmer},
  'educator': {"id": "educator", "configuration": agents_config["educator"], "agent": educator},
  #'executor': {"id": "executor", "configuration": agents_config["executor"], "agent": executor},
}
#print("agents_dict: ",agents_dict)
tasks_dict = {
  'research_task': {"id": "research_task", "configuration": tasks_config["research_task"], "task": research_task},
  'reporting_task': {"id": "reporting_task", "configuration": tasks_config["reporting_task"], "task": reporting_task},
  'code_task': {"id": "code_task", "configuration": tasks_config["code_task"], "task": code_task},
  'education_task': {"id": "education_task", "configuration": tasks_config["education_task"], "task": education_task},
  'generate_quiz_task':{"id": "generate_quiz_task", "configuration": tasks_config["generate_quiz_task"], "task": generate_quiz_task},
}
# --- å·¥å…·å‡½æ•° ---
# è·å–å¯¹è¯çš„è·¯å¾„
def get_convo_path(cid):
    return os.path.join(STORAGE_PATH, f'{cid}.json')

# åŠ è½½å¯¹è¯å†å²
def load_conversation(cid):
    path = get_convo_path(cid)
    if os.path.exists(path):
        with open(path, 'r') as f:
            return json.load(f)
    return []

# ä¿å­˜å¯¹è¯å†å²
def save_conversation(cid, history):
    with open(get_convo_path(cid), 'w') as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


session_store = {}

def get_or_create_session(conversation_id):
    if conversation_id not in session_store:
   
        crew = build_my_crew()
        session_store[conversation_id] = {
            "crew": crew,
            "memory": [],
            "history": load_conversation(conversation_id)
        }
    return session_store[conversation_id]

# åŒ¹é… ANSI è½¬ä¹‰åºåˆ—çš„æ­£åˆ™
ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
#box_drawing = re.compile(r'[â”€â•®â•¯â•°â”‚â•­â•®â•¯â•°]+')
# æ¸…é™¤é¢œè‰²æ§åˆ¶å­—ç¬¦
def strip_ansi(text):
    return ansi_escape.sub('', text)
def clear_queue(q: queue.Queue):
    while not q.empty():
        try:
            q.get_nowait()
        except queue.Empty:
            break

class WordStream(io.StringIO):
    def __init__(self):
        super().__init__()
        self.result_buffer = ""
        self.thought_buffer = ""
        self.raw_thought_lines = []  # ğŸ‘ˆ ä¿å­˜æ¯è¡Œæ—¥å¿—

    def write(self, s):
        self.result_buffer += s
        self.thought_buffer += s
        # å®æ—¶æ”¶é›†ï¼Œä½†ä¸æ¨é€
        lines = s.splitlines(keepends=True)
        for line in lines:
            if line.strip():
                self.raw_thought_lines.append(line)

    def get_thought(self):
        return "\n".join(self.raw_thought_lines)

    def get_result(self):
        return strip_ansi(self.result_buffer)



def scan_output_files():
    output_dir = Path("output")
    return set(str(f) for f in output_dir.glob("*") if f.is_file())


# def summarize_thoughts_stream(thought_text):
#     from openai import OpenAI  # æˆ–å…¶ä»–ä½ ç”¨çš„ LLM æ¥å£
#     import openai

#     client = openai.OpenAI(api_key=os.environ["OPENROUTER_API_KEY"],base_url=os.environ["BASE_URL"])

#     # ç”¨ streaming æ¨¡å¼è°ƒç”¨æ¨¡å‹æ€»ç»“
#     response = client.chat.completions.create(
#         model=os.environ["OTHER_MODEL"],  # or gpt-4o-mini
#         messages=[
#             {
#                 "role": "system",
#                 "content": (
#                     "ä½ æ˜¯ä¸€ä¸ª AI è§‚å¯Ÿè®°å½•å‘˜ï¼Œè´Ÿè´£å°†å¤šä½ AI Agent çš„ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ï¼Œ"
#                     "ä»¥ç»“æ„æ¸…æ™°ã€å®¹æ˜“ç†è§£çš„æ ¼å¼æ€»ç»“å‡ºæ¥ã€‚"
#                     "\n\n"
#                     "ä½ åº”è¯¥æ¨¡ä»¿ CrewAI çš„ `thought` æ—¥å¿—é£æ ¼ï¼Œç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œä½†è¦é€»è¾‘æ¸…æ¥šã€ç®€æ˜æ˜“æ‡‚ã€‚\n"
#                     "è¯·ä½¿ç”¨ä»¥ä¸‹ç»“æ„æ¥ç»„ç»‡è¾“å‡ºï¼š\n"
#                     "1. æ€»è§ˆï¼šæœ¬æ¬¡ä»»åŠ¡çš„ä¸»è¦ç›®æ ‡æ˜¯ä»€ä¹ˆï¼›\n"
#                     "2. åˆ†é…ï¼šå“ªäº› Agent è¢«åˆ†é…åˆ°å“ªäº›ä»»åŠ¡ï¼›\n"
#                     "3. æ‰§è¡Œï¼šå„ä¸ª Agent æ˜¯å¦‚ä½•æ‰§è¡Œè¿™äº›ä»»åŠ¡çš„ï¼Œæœ‰æ²¡æœ‰ä½¿ç”¨å·¥å…·ï¼Œå·¥å…·è¾“å‡ºäº†ä»€ä¹ˆï¼›\n"
#                     "4. ç»“æœç®€è¿°ï¼šæ€»ç»“æ•´ä½“è¾“å‡ºç»“æœï¼Œæ˜¯å¦æˆåŠŸï¼Œæ˜¯å¦äº§ç”Ÿæ–‡ä»¶ï¼›\n"
#                     "5. è‹¥æœ‰å¿…è¦ï¼Œè¡¥å……å…³é”®é€»è¾‘æˆ–æ³¨æ„äº‹é¡¹ã€‚\n\n"
#                     "é£æ ¼ä¸Šå¯ä»¥æ¨¡ä»¿ CrewAI æ€è€ƒæ—¥å¿—ï¼Œä½†è¦æ›´æ¸…æ¥šæ›´é€‚åˆç”¨æˆ·é˜…è¯»ï¼Œä¸è¦é€å­—å¤è¿°åŸå§‹è¾“å‡ºã€‚"
#                 )
#             },
#             {
#                 "role": "user",
#                 "content": (
#                     f"ä»¥ä¸‹æ˜¯ AI agents åœ¨ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„åŸå§‹æ—¥å¿—ï¼š\n\n{thought_text}\n\n"
#                     "è¯·æ ¹æ®ä¸Šé¢ç»“æ„æ€»ç»“è¾“å‡ºï¼š"
#                 )
#             }
#         ],
#         stream=True,
#         temperature=0.5
#     )
    
#     # æµå¼è¿”å›
#     for chunk in response:
#         delta = chunk.choices[0].delta
#         if hasattr(delta, "content") and delta.content:
#             yield json.dumps({"type": "thought", "data": delta.content}, ensure_ascii=False) + "\n"

def run_chatcrew_and_stream(crew: Crew, inputs: dict,session:dict,cid:str):
    original_stdout = sys.stdout
    word_stream = WordStream()
    sys.stdout = word_stream
    #files_before = set(scan_output_files())  # æ‰§è¡Œå‰æ–‡ä»¶åˆ—è¡¨

    def run():
        try:
            result = crew.kickoff(inputs=inputs)  # è°ƒç”¨ä½ è‡ªå·±çš„ CrewAI å®ä¾‹
            session["final_result"] = result.raw
            
            for i in range(0, len(result.raw), 3):
                chunk = result.raw[i:i+3]
                log_queue_result.put({"type": "result", "data": chunk})
        except Exception as e:
            err = f"[ERROR] {str(e)}"
            log_queue_result.put({"type": "result", "data": f"[ERROR] {str(e)}"})
            session["final_result"] = err


    thread = threading.Thread(target=run)
    thread.start()

    try:
        while thread.is_alive() or not log_queue_thought.empty():
            for line in word_stream.raw_thought_lines:
                log_queue_thought.put({"type": "raw_thought", "data": strip_ansi(line)})
            word_stream.raw_thought_lines.clear()
            try:
                item = log_queue_thought.get(timeout=0.1)
                yield json.dumps(item, ensure_ascii=False) + "\n"
            except queue.Empty:
                continue
        # #  ä»»åŠ¡å®Œæˆåï¼Œæ€»ç»“ execution thought
        # execution_thought = word_stream.get_thought()
        # session["execution_thought"] = execution_thought

        
        # for chunk in summarize_thoughts_stream(execution_thought):
        #     parsed = json.loads(chunk)
        #     if parsed.get("type") == "thought":
        #         log_queue_thought.put(parsed)  # ä¼˜å…ˆå±•ç¤º thought

        # #  è¾“å‡º summary thought
        # while not log_queue_thought.empty():
        #     yield json.dumps(log_queue_thought.get(timeout=0.5), ensure_ascii=False) + "\n"
            
            

        #  è¾“å‡º resultï¼ˆåœ¨ thought ä¹‹åï¼‰
        while not log_queue_result.empty():
            yield json.dumps(log_queue_result.get(timeout=2), ensure_ascii=False) + "\n"

        # files_after = scan_output_files()
        # new_files = files_after - files_before
        # if new_files:
        #     file_infos = [{"filename": f, "download_url": f"{f}"} for f in new_files]
        #     session["file_infos"] = file_infos
        #     yield json.dumps({"type": "file_list", "files": file_infos}, ensure_ascii=False) + "\n"


    finally:
        # è¿˜åŸ stdout
        sys.stdout = original_stdout
        session["history"].append({"role": "assistant", "content": session.get("final_result", ""),})
        save_conversation(cid, session["history"])

# å®æ—¶è¿è¡Œ crew å¹¶æŠŠè¾“å‡ºæ”¾åˆ°é˜Ÿåˆ—ä¸­
def run_crewai_and_stream(crew: Crew, inputs: dict,session:dict,cid:str):
    original_stdout = sys.stdout
    word_stream = WordStream()
    sys.stdout = word_stream
    files_before = set(scan_output_files())  # æ‰§è¡Œå‰æ–‡ä»¶åˆ—è¡¨

    def run():
        try:
            result = crew.kickoff(inputs=inputs)  # è°ƒç”¨ä½ è‡ªå·±çš„ CrewAI å®ä¾‹
            session["final_result"] = result.raw
            
            for i in range(0, len(result.raw), 3):
                chunk = result.raw[i:i+3]
                log_queue_result.put({"type": "result", "data": chunk})
        except Exception as e:
            err = f"[ERROR] {str(e)}"
            log_queue_result.put({"type": "result", "data": f"[ERROR] {str(e)}"})
            session["final_result"] = err


    thread = threading.Thread(target=run)
    thread.start()

    try:
        while thread.is_alive() or not log_queue_thought.empty():
            for line in word_stream.raw_thought_lines:
                log_queue_thought.put({"type": "raw_thought", "data": strip_ansi(line)})
            word_stream.raw_thought_lines.clear()
            try:
                item = log_queue_thought.get(timeout=0.1)
                yield json.dumps(item, ensure_ascii=False) + "\n"
            except queue.Empty:
                continue
        #  ä»»åŠ¡å®Œæˆåï¼Œæ€»ç»“ execution thought
        execution_thought = word_stream.get_thought()
        session["execution_thought"] = execution_thought

        
        # for chunk in summarize_thoughts_stream(execution_thought):
        #     parsed = json.loads(chunk)
        #     if parsed.get("type") == "thought":
        #         log_queue_thought.put(parsed)  # ä¼˜å…ˆå±•ç¤º thought

        # #  è¾“å‡º summary thought
        # while not log_queue_thought.empty():
        #     yield json.dumps(log_queue_thought.get(timeout=0.5), ensure_ascii=False) + "\n"
            
            

        # #  è¾“å‡º resultï¼ˆåœ¨ thought ä¹‹åï¼‰
        # while not log_queue_result.empty():
        #     yield json.dumps(log_queue_result.get(timeout=0.5), ensure_ascii=False) + "\n"

        # files_after = scan_output_files()
        # new_files = files_after - files_before
        # if new_files:
        #     file_infos = [{"filename": f, "download_url": f"{f}"} for f in new_files]
        #     session["file_infos"] = file_infos
        #     yield json.dumps({"type": "file_list", "files": file_infos}, ensure_ascii=False) + "\n"


    finally:
        # è¿˜åŸ stdout
        sys.stdout = original_stdout
        # è·å–æœ€ç»ˆç”Ÿæˆç»“æœå¹¶å­˜å…¥å†…å­˜ + history
        # print("####################excu##########")
        # print(session["final_result"])
        

        files_after = scan_output_files()
        new_files = files_after - files_before
        if new_files:
            #session['file_flag']=True
            file_infos = []
            for file in new_files:
                file_infos.append({
                        "filename": file,
                        "download_url": f"{file}"
                    })
            #print("####################file_infos##########")
            #print(file_infos)
            #  é€šçŸ¥å‰ç«¯æ–‡ä»¶ä¿¡æ¯

            # yield json.dumps({
            #     "type": "file_list",
            #     "files": file_infos
            # }, ensure_ascii=False) + "\n"
            session['file_infos']=file_infos


def run_planner_and_stream(planner_crew: Crew, inputs: dict, session: dict):
    original_stdout = sys.stdout
    word_stream = WordStream()
    sys.stdout = word_stream
    

    def run():
        try:
            result = planner_crew.kickoff(inputs=inputs)
            session["planner_output"] = result.raw
            
        except Exception as e:
            session["planner_output"] = f"[ERROR] {str(e)}"
        #     for i in range(0, len(result.raw), 3):
        #         log_queue_result.put({"type": "result", "data": result.raw[i:i+3]})
        # except Exception as e:
        #     log_queue_result.put({"type": "result", "data": f"[ERROR] {str(e)}"})

    thread = threading.Thread(target=run)
    thread.start()

    try:
        while thread.is_alive() or not log_queue_thought.empty():
            # å®æ—¶å°† WordStream ä¸­çš„ thought é€å…¥ log_queue_thought
            for line in word_stream.raw_thought_lines:
                log_queue_thought.put({"type": "raw_thought", "data": strip_ansi(line)})
            word_stream.raw_thought_lines.clear()
            try:
                # è¾“å‡ºå‰é¢ planner é˜¶æ®µäº§ç”Ÿçš„ thought æ—¥å¿—
                yield json.dumps(log_queue_thought.get(timeout=0.1), ensure_ascii=False) + "\n"
            except queue.Empty:
                continue
        #  æ€»ç»“ planner æ€è€ƒï¼Œæ’å…¥åˆ° thought é˜Ÿåˆ—ä¸­ï¼ˆä¼˜å…ˆè¾“å‡ºï¼‰

        planner_thought = word_stream.get_thought()
        session["planner_thought"] = planner_thought
        # for chunk in summarize_thoughts_stream(planner_thought):
        #     parsed = json.loads(chunk)
        #     if parsed.get("type") == "thought":
        #         log_queue_thought.put(parsed)

        # # å°†æœ€ç»ˆ summary ä¹Ÿ yield å‡ºå»
        # while not log_queue_thought.empty():
        #     yield json.dumps(log_queue_thought.get(timeout=0.5), ensure_ascii=False) + "\n"
    finally:
        sys.stdout = original_stdout

def run_code_analysis_and_stream(crew: Crew, inputs: dict, session: dict, cid: str):
    original_stdout = sys.stdout
    word_stream = WordStream()
    sys.stdout = word_stream
    files_before = set(scan_output_files())

    def run():
        try:
            result = crew.kickoff(inputs=inputs)
            session["final_result"] = result.raw
            for i in range(0, len(result.raw), 3):
                chunk = result.raw[i:i+3]
                log_queue_result.put({"type": "result", "data": chunk})
        except Exception as e:
            err = f"[ERROR] {str(e)}"
            session["final_result"] = err
            log_queue_result.put({"type": "result", "data": err})

    thread = threading.Thread(target=run)
    thread.start()

    try:
        # å®æ—¶è®°å½• raw thought æ—¥å¿—
        while thread.is_alive() or not log_queue_thought.empty():
            for line in word_stream.raw_thought_lines:
                log_queue_thought.put({"type": "raw_thought", "data": strip_ansi(line)})
            word_stream.raw_thought_lines.clear()
            try:
                item = log_queue_thought.get(timeout=0.1)
                yield json.dumps(item, ensure_ascii=False) + "\n"
            except queue.Empty:
                continue

        # æ€»ç»“ execution thought
        execution_thought = word_stream.get_thought()
        session["execution_thought"] = execution_thought
        summary_text = ""
        for chunk in summarize_thoughts_stream(execution_thought):
            parsed = json.loads(chunk)
            if parsed.get("type") == "thought":
                summary_text += parsed["data"]
                yield json.dumps(parsed, ensure_ascii=False) + "\n"

        # è¾“å‡º result
        while not log_queue_result.empty():
            yield json.dumps(log_queue_result.get(timeout=2), ensure_ascii=False) + "\n"

        # è¾“å‡ºæ–‡ä»¶åˆ—è¡¨
        files_after = scan_output_files()
        new_files = files_after - files_before
        if new_files:
            file_infos = [{"filename": f, "download_url": f"{f}"} for f in new_files]
            session["file_infos"] = file_infos
            yield json.dumps({"type": "file_list", "files": file_infos}, ensure_ascii=False) + "\n"

        # ä¿å­˜å†å²
        session["history"].append({
            "role": "assistant",
            "content": session.get("final_result", ""),
            "thought": summary_text,
            "files": session.get("file_infos", [])
        })
        save_conversation(cid, session["history"])

    finally:
        sys.stdout = original_stdout


def build_my_crew():
    # åˆ›å»ºå†…å­˜å¹¶å…±äº«ç»™æ‰€æœ‰ agent
    #memory = build_memory_from_history(history)

    crew = Crew(agents=[planner,researcher,reporting_analyst,programmer,educator], 
                tasks=[research_task, reporting_task,code_task,education_task],process=Process.sequential, verbose=True)  # è‡ªå®šä¹‰å‡½æ•°ï¼Œè¿”å› crew å¯¹è±¡
    return crew

def format_history(history):
    return "\n".join([
        f"{msg['role']}: {msg['content']}" for msg in history
    ])
import re
def extract_json_from_text(text):
    try:
        # æå–æœ€å¤–å±‚ JSON
        match = re.search(r'\{.*\}', text, re.DOTALL)
        if match:
            return json.loads(match.group())
        else:
            raise ValueError("No JSON object found")
    except json.JSONDecodeError as e:
        raise ValueError(f"JSON Decode Error: {e}")

# å‘é€æ¶ˆæ¯å¹¶æ›´æ–°å¯¹è¯å†å²
@app.route('/chat', methods=['POST'])
def chat():
    clear_queue(log_queue_thought)
    clear_queue(log_queue_result)
    cid = request.json['conversation_id']
    message = request.json['message'].strip()
    session = get_or_create_session(cid)
    #memory = session["memory"]
    #history = session["history"]
    if not message:
        return jsonify({"error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400
    
    
    
    session["history"].append({"role": "user", "content": message})
    save_conversation(cid, session["history"])



    # ---------------------- è‡ªåŠ¨åˆ¤æ–­æ˜¯å¦æ˜¯é—²èŠ/é—®å€™ ----------------------
    if should_greet_or_chitchat(message):  #  è‡ªåŠ¨ä½¿ç”¨ LLM åˆ¤æ–­
        # æ„å»ºè½»é‡ Crew æ‰§è¡Œç®€å•é—®å€™ä»»åŠ¡
        execution_inputs = {
            "user_input": message,
            "context": format_history(session["history"]),
        }

        crew = Crew(
            agents=[chat_agent],
            tasks=[greeting_task],
            process=Process.sequential,
            verbose=True
        )
        return Response(
            stream_with_context(
                run_chatcrew_and_stream(
                    crew=crew,
                    inputs=execution_inputs,
                    session=session,
                    cid=cid
                )
            ),
            mimetype="text/plain"
        )

    # ---------------------- è¿›å…¥æ­£å¸¸ planner åˆ†é…æµç¨‹ ----------------------

    planner_inputs = {
        "user_input": message,
        "context": format_history(session["history"]),
        "agents": json.dumps({
            "Agents": [{"id": item["id"], "configuration": item["configuration"]} 
                       for item in agents_dict.values()]
                },ensure_ascii=False),
        "tasks": json.dumps({
            "Tasks": [{"id": item["id"], "configuration": item["configuration"]} 
                      for item in tasks_dict.values()]
                },ensure_ascii=False),
    }
    # print(">>>> AGENTS JSON >>>>")
    # print(planner_inputs["agents"])
    # print(">>>> TASKS JSON >>>>")
    # print(planner_inputs["tasks"])

    def multi_stage_streaming():
        # Step 1: Planner

        manager_crew = Crew(
            agents=[planner],
            tasks=[distribute_task],
            process=Process.sequential,
            verbose=True
        )
        yield from run_planner_and_stream(manager_crew, planner_inputs, session)
 
        # Step 2: Parse Planner Result
        try:
            #print(session.get("planner_output", "{}"))
            parsed = extract_json_from_text(session.get("planner_output", ""))
            #print("#######")
            #print(parsed)
            agent_ids = [a["id"] for a in parsed["distribution_config"]["agents"]]
            task_ids = [t["id"] for t in parsed["distribution_config"]["tasks"]]

            log_queue_thought.put({"type": "thought", "data": f"\n[ Planner åˆ†é…ç»“æœ] ä½¿ç”¨ Agent: {agent_ids}, ä»»åŠ¡: {task_ids}\n"})
            json.dumps({"type": "thought", "data": f"\n[ Planner åˆ†é…ç»“æœ] ä½¿ç”¨ Agent: {agent_ids}, ä»»åŠ¡: {task_ids}\n"}, ensure_ascii=False) + "\n"
            dynamic_agents = [agents_dict[aid]["agent"] for aid in agent_ids]
            dynamic_tasks = [tasks_dict[tid]["task"] for tid in task_ids]
        except Exception as e:
            yield json.dumps({"type": "thought", "data": f"[ERROR]: {str(e)}"}, ensure_ascii=False) + "\n"
            return

        # Step 3: æ‰§è¡Œä»»åŠ¡
        execution_inputs = {
            "user_input": message,
            "context": format_history(session["history"]),
        }
        execution_crew = Crew(
            agents=dynamic_agents,
            tasks=dynamic_tasks,
            process=Process.sequential,
            verbose=True
        )

        yield from run_crewai_and_stream(execution_crew, execution_inputs, session, cid)
        #session["execution_thought"] = exec_stream.get_thought()


        # Step 4: æ€»ç»“ Planner + Execution
        full_thought = (
            session.get("planner_thought", "") + "\n" +
            session.get("execution_thought", "")
        )
        summary_text = ""
        for chunk in summarize_thoughts_stream(full_thought):
            parsed = json.loads(chunk)
            if parsed.get("type") == "thought":
                summary_text += parsed["data"]
                # æ€»ç»“ä¹Ÿä¼ªè£…æˆ Thought Log æå‰è¾“å‡º
                yield json.dumps(parsed, ensure_ascii=False) + "\n"
         # Step 5: result è¾“å‡º
        while not log_queue_result.empty():
            yield json.dumps(log_queue_result.get(timeout=2), ensure_ascii=False) + "\n"

        # Step 6: æ–‡ä»¶
        if "file_infos" in session:
            yield json.dumps({
                "type": "file_list",
                "files": session["file_infos"]
            }, ensure_ascii=False) + "\n"

        # Step 7: ä¿å­˜å†å²
        session["history"].append({
            "role": "assistant",
            "content": session.get("final_result", ""),
            "thought": summary_text,
            "files": session.get("file_infos", [])
        })
        
        save_conversation(cid, session["history"])


    return Response(
        stream_with_context(multi_stage_streaming()),
        mimetype="text/plain"
    )

@app.route('/output/<filename>', methods=['GET'])
def download_output_file(filename):
    return send_from_directory('output', filename, as_attachment=True)

@app.route("/upload_code", methods=["POST"])
def upload_code():
    file = request.files["file"]
    cid = request.form["conversation_id"]
    session = get_or_create_session(cid)

    # æ–‡ä»¶æ³¨å…¥åˆ°å†å²
    code = file.read().decode("utf-8")
    code_msg = f"ç”¨æˆ·ä¸Šä¼ äº†ä¸€æ®µä»£ç å¦‚ä¸‹ï¼š\n```python\n{code}\n```"
    session["history"].append({"role": "user", "content": code_msg})
    save_conversation(cid, session["history"])

    return jsonify({"message": "ä»£ç å·²æ³¨å…¥ä¸Šä¸‹æ–‡æˆåŠŸ"})


@app.route('/execute_code_snippet', methods=['POST'])
def execute_code_snippet():
    cid = request.form["conversation_id"]
    session = get_or_create_session(cid)

    if 'file' not in request.files:
        return jsonify({"error": "æœªæä¾›æ–‡ä»¶"}), 400
    file = request.files["file"]
    if file.filename == '':
        return jsonify({"error": "æ–‡ä»¶åä¸ºç©º"}), 400

    # ä¿å­˜æ–‡ä»¶
    save_path = os.path.join(OUTPUT_DIR, file.filename)
    file.save(save_path)
    # print(save_path)

    # ä¿å­˜æ–‡ä»¶å†…å®¹åˆ°å†å²ä¸­ï¼ˆmarkdownï¼‰
    with open(save_path, "r", encoding="utf-8") as f:
        code_content = f.read()
    #print(code_content)
    session["history"].append({
        "role": "user",
        "content": f"```python\n{code_content}\n```"
    })
    save_conversation(cid, session["history"])

    # æ„é€  Crew
    direct_crew = Crew(
        agents=[executor],
        tasks=[code_analysis_task],
        process=Process.sequential,
        verbose=True
    )

    # æ¸…ç©ºé˜Ÿåˆ—
    clear_queue(log_queue_thought)
    clear_queue(log_queue_result)

    # å¯åŠ¨æµå¼å“åº”ï¼ˆè°ƒç”¨æ–°å‡½æ•°ï¼‰
    return Response(
        stream_with_context(
            run_code_analysis_and_stream(
                crew=direct_crew,
                inputs={"path": save_path},
                session=session,
                cid=cid
            )
        ),
        mimetype="text/plain"
    )



@app.route('/submit_code', methods=['POST'])
def submit_code():
    data = request.json
    code = data.get("code", "")

    if not code:
        return jsonify({"error": "æœªæäº¤ä»£ç "}), 400

    # é€šè¿‡ CrewAI è°ƒåº¦ä»»åŠ¡æ‰§è¡Œ
    crew = build_my_crew()
    result, suggestion = crew.kickoff(inputs={"code": code})

    return jsonify({
        "result": result,
        "suggestions": suggestion
    })


# --- é¡µé¢è·¯ç”± ---
# @app.route("/")
# def index():
#     return render_template("index2.html")


# --- ä¼šè¯ç®¡ç† ---
@app.route('/new_conversation', methods=['POST'])
def new_conversation():
    user_id = request.json.get("user_id", "default")
    message = request.json.get("message", "")
    cid = str(uuid.uuid4())
    save_conversation(cid, [])
    return jsonify({"conversation_id": cid, "title":message[:50]})


@app.route('/conversations', methods=['GET'])
def get_conversations():
    if not os.path.exists(STORAGE_PATH):
        return jsonify([])

    conversations = []
    for filename in os.listdir(STORAGE_PATH):
        if filename.endswith(".json") and not filename.endswith(".meta.json"):
            cid = filename.replace(".json", '')
            title = "(æœªå‘½å)"

            meta_path = os.path.join(STORAGE_PATH, f"{cid}.meta.json")
            if os.path.exists(meta_path):
                with open(meta_path, "r", encoding="utf-8") as f:
                    metadata = json.load(f)
                    title = metadata.get("title", title)
            else:
                # å…¼å®¹æ—§æ–‡ä»¶ï¼šå°è¯•è¯»å–ç¬¬ä¸€å¥è¯
                try:
                    with open(os.path.join(STORAGE_PATH, filename), "r", encoding="utf-8") as f:
                        history = json.load(f)
                        title = next((m["content"] for m in history if m["role"] == "user"), title)
                except:
                    pass

            conversations.append({
                "id": cid,
                "title": title.strip()
            })

    return jsonify(conversations)


#è·å–å¯¹è¯å†å²   
@app.route('/conversation/<cid>', methods=['GET'])
def get_conversation_history(cid):
    convo_path = get_convo_path(cid)

    if not os.path.exists(convo_path):
        return jsonify({"error": "å¯¹è¯ä¸å­˜åœ¨"}), 404

    with open(convo_path, "r", encoding="utf-8") as f:
        try:
            history = json.load(f)
        except json.JSONDecodeError:
            return jsonify({"error": "å¯¹è¯æ•°æ®æ ¼å¼é”™è¯¯"}), 500

    return jsonify(history)


@app.route("/answer",methods=["GET"])
def answer():
    message = request.args.get("message", "")
    #message = data["message"]
    # è¿™é‡Œä½ åº”è¯¥æå‰æ„å»ºå¥½ crew å®ä¾‹å’Œ inputs å‚æ•°
    crew = build_my_crew()  # è‡ªå®šä¹‰å‡½æ•°ï¼Œè¿”å› crew å¯¹è±¡
    inputs = {"topic": message}  # ç¤ºä¾‹ inputs
    return Response(
        stream_with_context(run_crewai_and_stream(crew, inputs)),
        mimetype="text/plain"
    )

#åˆ é™¤å¯¹è¯
@app.route("/delete_conversation/<cid>", methods=["DELETE"])
def delete_conversation(cid):
    convo_path = get_convo_path(cid)

    if os.path.exists(convo_path):
        os.remove(convo_path)

    return jsonify({"success": True})


if __name__ == "__main__":
    app.run(debug=False,host='0.0.0.0',port=5000)
